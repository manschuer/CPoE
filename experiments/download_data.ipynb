{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.datasets import fetch_openml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.io # for directly downloading .mat files\n",
    "import pyreadr  # for directly downloading .rda files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook shows how to get the public datasets used in the paper CPoE. In particular, the datasets are downloaded, the inputs and outputs are selected and standarized. Finally, they are stored as .csv data all in the same format which are then used as input for the algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## i) get datasets from LIBSSVM dataset repository \n",
    "#### (which is based on other data repositories such as UCI,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "url_dict = {\n",
    "    'abalone':'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/abalone',\n",
    "    'cadata':'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/cadata',\n",
    "    'mg':'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/mg',\n",
    "    'space_ga':'https://www.csie.ntu.edu.tw/~cjlin/libsvmtools/datasets/regression/space_ga'\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name in ['abalone', 'cadata', 'mg', 'space_ga']:\n",
    "    \n",
    "    # read csv file from url\n",
    "    data = pd.read_csv(url_dict[name], sep=' ', header=None)\n",
    "    \n",
    "    # response/output\n",
    "    yy = np.array(data.iloc[:,0])\n",
    "\n",
    "    # select inputs\n",
    "    XX = np.hstack([ np.array([np.float(it[2:]) for it in np.array(data.iloc[:,col])])[:,None] for col in np.arange(1,data.shape[1]) ])\n",
    "\n",
    "    # scale and store as csv with same format\n",
    "    GG = np.hstack([XX, yy[:,None]])\n",
    "    df = StandardScaler().fit_transform(np.array(GG))\n",
    "    pd.DataFrame(df).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ii) get datasets from open ML repository\n",
    "#### (which is based on other data sources such as UCI,...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'kin8nm'\n",
    "# download data and select rows for input and output\n",
    "data0 = fetch_openml('kin8nm', version=1)\n",
    "DF = data0['data']\n",
    "DF['y'] = data0['target']\n",
    "\n",
    "# standarize and save\n",
    "df = StandardScaler().fit_transform(DF)\n",
    "pd.DataFrame(df).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'concrete'\n",
    "# download data and select rows for input and output\n",
    "data0 = fetch_openml('Concrete_Data')\n",
    "DF = data0['data']\n",
    "\n",
    "# standarize and save\n",
    "df = StandardScaler().fit_transform(DF)\n",
    "pd.DataFrame(df).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'casp'\n",
    "# download data and select rows for input and output\n",
    "data0 = fetch_openml('physicochemical-protein')\n",
    "DF = data0['data'][['F'+str(i) for i in range(1,10)]]\n",
    "DF['y'] = data0['data']['RMSD']\n",
    "\n",
    "# standarize and save\n",
    "df = StandardScaler().fit_transform(DF)\n",
    "pd.DataFrame(df).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iii) get sarcos dataset from Gaussianprocess.org"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'sarcos'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-22 13:40:42--  http://gaussianprocess.org/gpml/data/sarcos_inv.mat?raw=true\n",
      "Resolving gaussianprocess.org (gaussianprocess.org)... 185.199.108.153\n",
      "Connecting to gaussianprocess.org (gaussianprocess.org)|185.199.108.153|:80... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 9964616 (9.5M) [application/octet-stream]\n",
      "Saving to: ‘sarcos_inv.mat?raw=true’\n",
      "\n",
      "sarcos_inv.mat?raw= 100%[===================>]   9.50M  1.20MB/s    in 10s     \n",
      "\n",
      "2022-11-22 13:40:53 (962 KB/s) - ‘sarcos_inv.mat?raw=true’ saved [9964616/9964616]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get matlab file\n",
    "!wget http://gaussianprocess.org/gpml/data/sarcos_inv.mat?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create unified .csv file\n",
    "mat = scipy.io.loadmat('sarcos_inv.mat?raw=true')\n",
    "df = StandardScaler().fit_transform(np.array(mat['sarcos_inv'][:,:22])) # as done in several GP papers\n",
    "pd.DataFrame(df).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove matlab file\n",
    "!rm sarcos_inv.mat?raw=true"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## iv) get elecdemand dataset from fpp2 package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'elecdemand'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2022-11-22 13:40:55--  https://github.com/robjhyndman/fpp2-package/raw/master/data/elecdemand.rda\n",
      "Resolving github.com (github.com)... 140.82.121.3\n",
      "Connecting to github.com (github.com)|140.82.121.3|:443... connected.\n",
      "HTTP request sent, awaiting response... 302 Found\n",
      "Location: https://raw.githubusercontent.com/robjhyndman/fpp2-package/master/data/elecdemand.rda [following]\n",
      "--2022-11-22 13:40:55--  https://raw.githubusercontent.com/robjhyndman/fpp2-package/master/data/elecdemand.rda\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.111.133, 185.199.108.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 143201 (140K) [application/octet-stream]\n",
      "Saving to: ‘elecdemand.rda’\n",
      "\n",
      "elecdemand.rda      100%[===================>] 139.84K  --.-KB/s    in 0.1s    \n",
      "\n",
      "2022-11-22 13:40:56 (1.36 MB/s) - ‘elecdemand.rda’ saved [143201/143201]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get .rda dataset\n",
    "!wget https://github.com/robjhyndman/fpp2-package/raw/master/data/elecdemand.rda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transfrom .rda file into panda dataframe\n",
    "result = pyreadr.read_r('elecdemand.rda') \n",
    "DF = result['elecdemand']\n",
    "# remove .rda file\n",
    "!rm elecdemand.rda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder so that target is last column\n",
    "DF = DF[['Temperature','WorkDay','Demand']]\n",
    "df = StandardScaler().fit_transform(DF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create time variable ranging from 0 to 1 [1 year]\n",
    "time = np.arange(1,DF.shape[0]+1)/(2*24*365) \n",
    "# and add it as first column\n",
    "mat = np.hstack( [time[:,None], df] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store it as unified .csv\n",
    "pd.DataFrame(mat).to_csv('datasets/DAT'+name+'.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load created .csv data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "concrete \n",
      "N = 1030 \n",
      "D = 8 \n",
      "\n",
      "mg \n",
      "N = 1385 \n",
      "D = 6 \n",
      "\n",
      "space_ga \n",
      "N = 3107 \n",
      "D = 6 \n",
      "\n",
      "abalone \n",
      "N = 4177 \n",
      "D = 8 \n",
      "\n",
      "kin8nm \n",
      "N = 8192 \n",
      "D = 8 \n",
      "\n",
      "cadata \n",
      "N = 20640 \n",
      "D = 8 \n",
      "\n",
      "sarcos \n",
      "N = 44484 \n",
      "D = 21 \n",
      "\n",
      "casp \n",
      "N = 45730 \n",
      "D = 9 \n",
      "\n",
      "elecdemand \n",
      "N = 17520 \n",
      "D = 3 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name in ['concrete', 'mg', 'space_ga','abalone', 'kin8nm','cadata','sarcos','casp','elecdemand' ]:\n",
    "    # load .csv data\n",
    "    data = np.array(pd.read_csv('datasets/DAT'+name+'.csv', index_col=0))\n",
    "    X = data[:,:-1]\n",
    "    y = data[:,-1]\n",
    "    \n",
    "    print(name, \"\\nN =\",len(y), \"\\nD =\",X.shape[1],'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
